"""
Streamlit ç‰ˆ Musk æ¨æ–‡æ¸…æ´— + äº¤äº’å¼åˆ†æå·¥ä½œå°ã€‚
è¿è¡Œï¼šstreamlit run å·¥ä½œå®¤è„šæœ¬/é¡¹ç›®/Polymarket/polymarket_web.py
"""

import tempfile
import requests
from datetime import datetime, timedelta, date, time
from pathlib import Path
from contextlib import contextmanager
from typing import Dict, Tuple, List
from zoneinfo import ZoneInfo

import altair as alt
import pandas as pd
import streamlit as st
import re
from pathlib import Path
import streamlit.components.v1 as components

BASE_DIR = Path(__file__).resolve().parent
DATA_DIR = BASE_DIR / "data"
DATA_DIR.mkdir(exist_ok=True)

WEEKDAY_MAP = {
    "å‘¨ä¸€": "Mon",
    "æ˜ŸæœŸä¸€": "Mon",
    "Mon": "Mon",
    "Monday": "Mon",
    "å‘¨äºŒ": "Tue",
    "æ˜ŸæœŸäºŒ": "Tue",
    "Tue": "Tue",
    "Tuesday": "Tue",
    "å‘¨ä¸‰": "Wed",
    "æ˜ŸæœŸä¸‰": "Wed",
    "Wed": "Wed",
    "Wednesday": "Wed",
    "å‘¨å››": "Thu",
    "æ˜ŸæœŸå››": "Thu",
    "Thu": "Thu",
    "Thursday": "Thu",
    "å‘¨äº”": "Fri",
    "æ˜ŸæœŸäº”": "Fri",
    "Fri": "Fri",
    "Friday": "Fri",
    "å‘¨å…­": "Sat",
    "æ˜ŸæœŸå…­": "Sat",
    "Sat": "Sat",
    "Saturday": "Sat",
    "å‘¨æ—¥": "Sun",
    "æ˜ŸæœŸæ—¥": "Sun",
    "å‘¨å¤©": "Sun",
    "Sun": "Sun",
    "Sunday": "Sun",
}

import polymarket

WEEKDAY_ORDER = ["Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"]
WEEKDAY_CN = {
    "Mon": "å‘¨ä¸€",
    "Tue": "å‘¨äºŒ",
    "Wed": "å‘¨ä¸‰",
    "Thu": "å‘¨å››",
    "Fri": "å‘¨äº”",
    "Sat": "å‘¨å…­",
    "Sun": "å‘¨æ—¥",
}
ANCHOR_DAYS = [4, 7, 11, 14, 18, 21, 25, 28]


@contextmanager
def glass_block(class_name: str = "glass-card"):
    st.markdown(f"<div class='{class_name}'>", unsafe_allow_html=True)
    yield
    st.markdown("</div>", unsafe_allow_html=True)


def midday_dt(day: date) -> datetime:
    """Convert a date to EST 12:00 PM (naive) datetime."""
    return datetime.combine(day, time()) + timedelta(hours=12)
SECTION_OPTIONS: Dict[str, str] = {
    "overview": "ğŸ” æ¦‚è§ˆï¼ˆå…¨éƒ¨ï¼‰",
    "daily": "ğŸ“† æ—¥è¶‹åŠ¿ï¼ˆè‡ªç„¶æ—¥ï¼‰",
    "weekly_cycle_total": "ğŸ“Š å†å² 7 æ—¥å‘¨æœŸæ€»é‡",
    "weekly_compare_day": "ğŸ“ˆ å†å² 7 æ—¥å‘¨æœŸå¯¹æ¯”ï¼ˆæ—¥çº§ï¼‰",
    "weekly_compare_hour": "ğŸ•’ å†å² 7 æ—¥å‘¨æœŸå¯¹æ¯”ï¼ˆå°æ—¶çº§ï¼‰",
    "hourly": "ğŸ•’ å°æ—¶è¶‹åŠ¿",
    "weekday": "ğŸ“… Weekday åˆ†å¸ƒ",
    "heatmap": "ğŸ§Š Weekday Ã— Hour",
    "insight": "ğŸ¤– è¡Œä¸ºæ´å¯Ÿ",
    "detail": "ğŸ“„ æ¸…æ´—æ˜ç»†",
}


def load_clean_outputs(clean_path: Path) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    """è¯»å–æ¸…æ´—æ˜ç»† + ç»Ÿè®¡ç»“æœå¹¶è¡¥å……å¿…è¦å­—æ®µã€‚"""
    detail_df = pd.read_csv(clean_path)
    detail_df["Beijing_dt"] = pd.to_datetime(
        detail_df["Beijing_time"].astype(str).str.replace(" CST", "", regex=False), errors="coerce"
    )
    detail_df["EST_dt"] = pd.to_datetime(
        detail_df["EDT_time"]
        .astype(str)
        .str.replace(" EDT", "", regex=False)
        .str.replace(" EST", "", regex=False),
        errors="coerce",
    )

    stats_path = clean_path.with_name(clean_path.name.replace(".csv", "_stats.xlsx"))
    day_df = pd.read_excel(stats_path, sheet_name="day_summary_12PM-12PM_EST")
    day_natural_df = pd.read_excel(stats_path, sheet_name="day_summary_natural_EST")
    hour_df = pd.read_excel(stats_path, sheet_name="hour_summary")

    day_df["date"] = pd.to_datetime(day_df["date"], format="%m/%d/%Y")
    day_natural_df["date"] = pd.to_datetime(day_natural_df["date"], format="%m/%d/%Y")
    if "week_day" not in day_natural_df.columns:
        day_natural_df["week_day"] = day_natural_df["date"].dt.strftime("%a")
    hour_df["date"] = pd.to_datetime(hour_df["date"], format="%m/%d/%Y")
    return detail_df, day_df, day_natural_df, hour_df


def ensure_file(uploaded, fetch_latest=False):
    """å¤„ç†ä¸Šä¼ /åœ¨çº¿æ‹‰å–çš„åŸå§‹æ•°æ®å¹¶è¿è¡Œæ¸…æ´—ï¼›è‹¥æ— è¾“å…¥åˆ™ä½¿ç”¨æœ€æ–° clean æ–‡ä»¶ã€‚"""
    temp_path = None
    source_info = None
    if fetch_latest:
        try:
            with st.spinner("æ­£åœ¨ä» XTracker æ‹‰å–æœ€æ–°æ•°æ®â€¦"):
                resp = requests.post(
                    "https://www.xtracker.io/api/download",
                    json={"handle": "elonmusk", "platform": "X"},
                    timeout=30,
                )
                resp.raise_for_status()
                with tempfile.NamedTemporaryFile(delete=False, suffix=".csv") as tmp:
                    tmp.write(resp.content)
                    temp_path = Path(tmp.name)
            source_info = {"mode": "åœ¨çº¿è¯»å–", "name": "XTracker"}
            st.success("å·²ä» XTracker æ‹‰å–æœ€æ–°æ•°æ®ï¼Œå¼€å§‹æ¸…æ´—â€¦")
        except Exception as exc:
            st.error(f"åœ¨çº¿æ‹‰å–å¤±è´¥ï¼š{exc}")
    elif uploaded:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".csv") as tmp:
            tmp.write(uploaded.getbuffer())
            temp_path = Path(tmp.name)
        source_info = {"mode": "æœ¬åœ°æ–‡ä»¶", "name": uploaded.name}
        st.success(f"å·²ä¸Šä¼  {uploaded.name}ï¼Œå¼€å§‹æ¸…æ´—â€¦")

    if temp_path:
        original_input = polymarket.INPUT_FILE
        try:
            polymarket.INPUT_FILE = str(temp_path)
            polymarket.run_cleaning()
        finally:
            polymarket.INPUT_FILE = original_input

    files = polymarket.list_clean_files()
    if not files:
        st.info("ğŸ‘† å…ˆä¸Šä¼  XTracker å¯¼å‡ºçš„ CSVï¼Œå®Œæˆæ¸…æ´—åå³å¯å±•ç¤ºã€‚")
        return None, {"mode": "æœªåŠ è½½", "name": "â€”"}
    latest = Path(files[0])
    st.success(f"å½“å‰ä½¿ç”¨ï¼š{latest.name}")
    if source_info is None:
        source_info = {"mode": "æœ¬åœ°ç¼“å­˜", "name": latest.name}
    return latest, source_info


def metrics_overview(day_bucket_df: pd.DataFrame, detail_df: pd.DataFrame):
    total = int(day_bucket_df["day_tweet_count"].sum()) if not day_bucket_df.empty else 0
    avg_day = float(day_bucket_df["day_tweet_count"].mean()) if not day_bucket_df.empty else 0.0
    busiest = (
        day_bucket_df.loc[day_bucket_df["day_tweet_count"].idxmax()]
        if not day_bucket_df.empty
        else None
    )
    cols = st.columns(3)
    cols[0].metric("æ€»æ¨æ–‡æ•°", f"{total:,}")
    cols[1].metric("æ—¥å‡æ¨æ–‡", f"{avg_day:.1f}")
    if busiest is not None:
        cols[2].metric("æœ€é«˜å³°", f"{busiest['day_tweet_count']} æ¡", busiest["date"].strftime("%Y-%m-%d"))
    else:
        cols[2].metric("æœ€é«˜å³°", "â€”")


def render_cst_clock():
    beijing_now = datetime.now(ZoneInfo("Asia/Shanghai"))
    now_est = datetime.now(ZoneInfo("America/New_York"))
    server_str = now_est.strftime("%Y/%m/%d %H:%M:%S")
    weekday = now_est.strftime("%A")
    beijing_str = beijing_now.strftime("%Y/%m/%d %H:%M:%S")
    est_by_delta = beijing_now - timedelta(hours=13)
    est_delta_str = est_by_delta.strftime("%Y/%m/%d %H:%M:%S")
    html_content = f"""
    <style>
      @keyframes pulseClock {{
        0% {{ opacity: 0.3; transform: scale(0.9); }}
        50% {{ opacity: 1; transform: scale(1); }}
        100% {{ opacity: 0.3; transform: scale(0.9); }}
      }}
      .clock-chip {{
        display: inline-flex;
        align-items: center;
        gap: 10px;
        padding: 8px 16px;
        border-radius: 16px;
        background: linear-gradient(120deg, #2563eb, #22d3ee);
        color: #fff;
        font-family: 'SF Pro Display', 'Segoe UI', sans-serif;
        font-size: 17px;
        font-weight: 600;
        box-shadow: 0 8px 20px rgba(37, 99, 235, 0.35);
      }}
      .clock-indicator {{
        width: 10px;
        height: 10px;
        border-radius: 50%;
        background: #fbbf24;
        box-shadow: 0 0 14px rgba(251, 191, 36, 0.85);
        animation: pulseClock 1.2s infinite;
      }}
      .clock-time {{ font-variant-numeric: tabular-nums; letter-spacing: 1px; }}
      .clock-body {{ display:flex; flex-direction:column; gap:2px; font-size:17px; }}
      .clock-rows {{ display:flex; flex-direction:column; gap:0px; }}
    </style>
    <div class='clock-chip'>
      <div class='clock-indicator'></div>
      <div class='clock-body'>
        <div>ğŸ‡ºğŸ‡¸ ç¾å›½ä¸œéƒ¨æ—¶é—´ï¼ˆESTï¼‰ï¼š<span id="cst-clock-text" class='clock-time'>{server_str}</span>
        (<span id="cst-clock-weekday">{weekday}</span>) ï½œ ğŸ‡¨ğŸ‡³ åŒ—äº¬æ—¶é—´ï¼š<span id="bj-clock-text">{beijing_str}</span></div>
      </div>
    </div>
    <script>
      const estFormatter = new Intl.DateTimeFormat('zh-CN', {{
        timeZone: 'America/New_York',
        year: 'numeric', month: '2-digit', day: '2-digit',
        hour: '2-digit', minute: '2-digit', second: '2-digit',
        hour12: false
      }});
      const weekdayFmt = new Intl.DateTimeFormat('en-US', {{ timeZone: 'America/New_York', weekday: 'long' }});
      const bjFormatter = new Intl.DateTimeFormat('zh-CN', {{
        timeZone: 'Asia/Shanghai',
        year: 'numeric', month: '2-digit', day: '2-digit',
        hour: '2-digit', minute: '2-digit', second: '2-digit',
        hour12: false
      }});
      function updateClock() {{
        const now = new Date();
        const estParts = estFormatter.formatToParts(now).reduce((acc, part) => {{
          if (part.type !== 'literal') acc[part.type] = part.value;
          return acc;
        }}, {{}});
        const estFormatted = `${{estParts.year}}/${{estParts.month}}/${{estParts.day}} ${{estParts.hour}}:${{estParts.minute}}:${{estParts.second}}`;
        const clockEl = document.getElementById('cst-clock-text');
        const weekdayEl = document.getElementById('cst-clock-weekday');
        if (clockEl) clockEl.textContent = estFormatted;
        if (weekdayEl) weekdayEl.textContent = weekdayFmt.format(now);

        const bjParts = bjFormatter.formatToParts(now).reduce((acc, part) => {{
          if (part.type !== 'literal') acc[part.type] = part.value;
          return acc;
        }}, {{}});
        const bjFormatted = `${{bjParts.year}}/${{bjParts.month}}/${{bjParts.day}} ${{bjParts.hour}}:${{bjParts.minute}}:${{bjParts.second}}`;
        const bjEl = document.getElementById('bj-clock-text');
        if (bjEl) bjEl.textContent = bjFormatted;
      }}
      updateClock();
      setInterval(updateClock, 1000);
    </script>
    """
    components.html(html_content, height=58)


def render_left_table(df: pd.DataFrame):
    if df.empty:
        st.info("æš‚æ— å¯å±•ç¤ºçš„æ•°æ®")
        return
    table_html = df.to_html(index=False, classes="hist-table", border=0, justify="left")
    html = f"""
    <style>
      table.hist-table {{ width: 100%; border-collapse: collapse; }}
      table.hist-table th, table.hist-table td {{
        text-align: left !important;
        padding: 6px 10px;
        border-bottom: 1px solid rgba(0,0,0,0.05);
        font-size: 13px;
        white-space: nowrap;
      }}
      .hist-wrapper {{
        max-height: 320px;
        overflow-y: auto;
        border: 1px solid rgba(0,0,0,0.05);
        border-radius: 10px;
        padding: 4px;
        background: rgba(255,255,255,0.6);
      }}
    </style>
    <div class='hist-wrapper'>{table_html}</div>
    """
    height = min(420, 80 + 26 * len(df))
    components.html(html, height=height)


def render_hour_matrix(cycles_meta: List[Dict]):
    if not cycles_meta:
        return
    rows = []
    hour_labels = [f"{h:02d}:00" for h in range(24)]
    for wd in WEEKDAY_ORDER:
        row = {"Weekday": wd}
        for hour in range(24):
            chunks = []
            for meta in cycles_meta:
                count = meta["data"].get((hour, wd), 0)
                if count > 0:
                    chunks.append(
                        f"<div class='cell-line'><span class='legend-dot' style='background:{meta['color']}'></span>{count}</div>"
                    )
            row[f"{hour:02d}:00"] = "".join(chunks)
        rows.append(row)
    df = pd.DataFrame(rows)

    legend_html = "".join(
        f"<span class='legend-item'><span class='legend-dot' style='background:{meta['color']}'></span>{meta['label']}</span>"
        for meta in cycles_meta
        if meta["data"]
    )

    table_html = df.to_html(index=False, escape=False, classes="hist-table matrix-table", justify="left", border=0)
    html = f"""
    <style>
      .matrix-container {{
        width: 100%;
        max-height: 480px;
        overflow: auto;
        border: 1px solid rgba(0,0,0,0.08);
        border-radius: 14px;
        padding: 6px;
        background: rgba(255,255,255,0.75);
      }}
      table.matrix-table {{ min-width: 1500px; border-collapse: collapse; }}
      table.matrix-table th, table.matrix-table td {{
        min-width: 110px;
        text-align: left !important;
        vertical-align: top;
        padding: 10px;
      }}
      table.matrix-table td {{ min-height: 56px; }}
      .cell-line {{ display: flex; align-items: center; gap: 6px; font-size: 13px; margin-bottom: 4px; }}
      .legend-dot {{ width: 10px; height: 10px; border-radius: 50%; display:inline-block; }}
      .matrix-legend {{ margin-bottom: 6px; font-size: 13px; display:flex; flex-wrap:wrap; gap:12px; }}
      .legend-item {{ display:flex; align-items:center; gap:6px; }}
    </style>
    <div class='matrix-legend'>{legend_html}</div>
    <div class='matrix-container'>{table_html}</div>
    """
    components.html(html, height=520)


def render_historical_today_table(
    current_df: pd.DataFrame,
    history_df: pd.DataFrame,
    history_cycles: int,
    hour_scope_df: pd.DataFrame,
    focus_date,
):
    if current_df is None or current_df.empty:
        st.info("æš‚æ— å½“å‰å‘¨æœŸæ•°æ®")
        return
    if isinstance(focus_date, datetime):
        focus_date = focus_date.date()
    current = current_df.copy()
    current["date"] = pd.to_datetime(current["date"]).dt.date
    available_dates = sorted(current["date"].unique())
    if available_dates:
        focus_date = max(d for d in available_dates if d <= focus_date) if any(
            d <= focus_date for d in available_dates
        ) else available_dates[-1]
    history = history_df.copy() if history_df is not None else pd.DataFrame(columns=["date", "day_tweet_count"])
    if not history.empty:
        history["date"] = pd.to_datetime(history["date"]).dt.date

    weekday = current.loc[current["date"] == focus_date, "week_day"]
    weekday = weekday.iloc[0] if not weekday.empty else focus_date.strftime("%a")
    weekday_cn = WEEKDAY_CN.get(weekday, weekday)
    st.markdown(f"#### ğŸ“œ å†å²ä¸Šçš„ä»Šå¤©ï¼ˆ0:00-24:00 ESTï¼Œ{weekday_cn}ï¼‰")

    rows: List[Dict[str, str]] = []
    current_count = int(current.loc[current["date"] == focus_date, "day_tweet_count"].sum())
    rows.append({"å‘¨æœŸ": f"æœ¬å‘¨æœŸï¼ˆ{focus_date.strftime('%m/%d')}ï¼‰", "æ¨æ–‡æ•°": current_count})

    for idx in range(1, history_cycles + 1):
        target_date = focus_date - timedelta(days=7 * idx)
        count = int(history.loc[history["date"] == target_date, "day_tweet_count"].sum())
        rows.append({"å‘¨æœŸ": f"å†å²å‘¨æœŸ {idx}ï¼ˆ{target_date.strftime('%m/%d')}ï¼‰", "æ¨æ–‡æ•°": count})

    render_left_table(pd.DataFrame(rows))

    if hour_scope_df is None or hour_scope_df.empty:
        return
    hour_scope = hour_scope_df.copy()
    hour_scope["date"] = pd.to_datetime(hour_scope["date"]).dt.date

    def build_hour_map(target_date):
        subset = hour_scope.loc[hour_scope["date"] == target_date]
        if subset.empty:
            return {}
        temp = subset.copy()
        temp_dates = pd.to_datetime(temp["date"])
        temp["week_day"] = temp_dates.dt.strftime("%a")
        temp["hour_us"] = temp["hour_us"].astype(int)
        grouped = temp.groupby(["hour_us", "week_day"])["hour_tweet_count"].sum()
        return grouped.to_dict()

    colors = ["#ef4444", "#0ea5e9", "#f97316", "#a855f7", "#10b981", "#facc15", "#ec4899"]
    cycles_meta = []
    cycles_meta.append(
        {
            "label": f"æœ¬å‘¨æœŸï¼ˆ{focus_date.strftime('%m/%d')}ï¼‰",
            "color": colors[0],
            "data": build_hour_map(focus_date),
        }
    )
    for idx in range(1, history_cycles + 1):
        target_date = focus_date - timedelta(days=7 * idx)
        cycles_meta.append(
            {
                "label": f"å†å²å‘¨æœŸ {idx}ï¼ˆ{target_date.strftime('%m/%d')}ï¼‰",
                "color": colors[idx % len(colors)],
                "data": build_hour_map(target_date),
            }
        )

    if any(meta["data"] for meta in cycles_meta):
        st.markdown("##### â± æŒ‰å°æ—¶åˆ†å¸ƒï¼ˆå‘¨Ã—å°æ—¶çŸ©é˜µï¼‰")
        render_hour_matrix(cycles_meta)


def render_day_section(
    day_df: pd.DataFrame,
    show_values: bool,
    title_suffix: str = "è‡ªç„¶æ—¥EST 0:00-23:59",
    history_df: pd.DataFrame | None = None,
    history_cycles: int = 0,
    base_range: Tuple[datetime.date, datetime.date] | None = None,
):
    st.subheader(f"ğŸ“† æ—¥è¶‹åŠ¿ï¼ˆ{title_suffix}ï¼‰")
    if day_df.empty:
        st.info("å½“å‰ç­›é€‰åŒºé—´å†…æ²¡æœ‰æ•°æ®")
        return
    ordered_labels = day_df.sort_values("date")["date"].dt.strftime("%m/%d (%a)").tolist()
    day_df = day_df.assign(label=day_df["date"].dt.strftime("%m/%d (%a)"))
    hover = alt.selection_point(fields=["label"], nearest=True, on="mouseover", empty="none")
    base_line = (
        alt.Chart(day_df)
        .mark_line(interpolate="monotone")
        .encode(
            x=alt.X(
                "label:N",
                title="",
                sort=ordered_labels,
                axis=alt.Axis(labelAngle=0),
            ),
            y=alt.Y("day_tweet_count:Q", title="Tweets per Day"),
        )
    )
    base_points = (
        alt.Chart(day_df)
        .mark_point(size=70)
        .encode(
            x="label:N",
            y="day_tweet_count:Q",
            tooltip=["label:N", "day_tweet_count:Q"],
        )
        .add_params(hover)
    )
    rule = (
        alt.Chart(day_df)
        .mark_rule(color="#888", strokeDash=[4, 4])
        .encode(x="label:N")
        .transform_filter(hover)
    )
    base = (base_line + base_points + rule)

    if (
        history_df is not None
        and base_range is not None
        and history_cycles > 0
        and not history_df.empty
        and ordered_labels
    ):
        hist_copy = history_df.copy()
        hist_copy["date"] = pd.to_datetime(hist_copy["date"]).dt.date
        history_lookup = hist_copy.set_index("date")["day_tweet_count"].to_dict()
        base_start = base_range[0]
        base_start = base_start.date() if isinstance(base_start, datetime) else base_start
        days_in_cycle = min(len(ordered_labels), 7)
        overlay_rows: List[Dict] = []
        for idx in range(1, history_cycles + 1):
            cycle_start = base_start - timedelta(days=7 * idx)
            cycle_end = cycle_start + timedelta(days=days_in_cycle - 1)
            cycle_label = f"{cycle_start.strftime('%m/%d')}â€“{cycle_end.strftime('%m/%d')}"
            for offset in range(days_in_cycle):
                label = ordered_labels[offset]
                target_date = cycle_start + timedelta(days=offset)
                count = int(history_lookup.get(target_date, 0))
                overlay_rows.append(
                    {
                        "label": label,
                        "count": count,
                        "cycle": cycle_label,
                        "actual_date": target_date.strftime("%Y-%m-%d"),
                    }
                )
        history_overlay_df = pd.DataFrame(overlay_rows)
        if not history_overlay_df.empty:
            history_overlay_df["label"] = pd.Categorical(
                history_overlay_df["label"], categories=ordered_labels, ordered=True
            )
            history_line = (
                alt.Chart(history_overlay_df)
                .mark_line(strokeDash=[4, 3], opacity=0.65)
                .encode(
                    x=alt.X("label:N", sort=ordered_labels, title="", axis=alt.Axis(labelAngle=0)),
                    y=alt.Y("count:Q", title="Tweets per Day"),
                    color=alt.Color(
                        "cycle:N",
                        title="å†å²å‘¨æœŸ",
                        legend=alt.Legend(orient="right"),
                        scale=alt.Scale(scheme="tableau10"),
                    ),
                )
            )
            history_points = (
                alt.Chart(history_overlay_df)
                .mark_point(size=50, opacity=0.7)
                .encode(
                    x=alt.X("label:N", sort=ordered_labels),
                    y="count:Q",
                    color=alt.Color("cycle:N", legend=None, scale=alt.Scale(scheme="tableau10")),
                    tooltip=["cycle:N", "label:N", "actual_date:N", "count:Q"],
                )
            )
            base = base + history_line + history_points

    base = base.properties(height=320).interactive()
    if show_values:
        text = (
            alt.Chart(day_df)
            .mark_text(dy=-10, fontSize=11)
            .encode(
                x=alt.X("label:N", sort=ordered_labels, axis=alt.Axis(labelAngle=0)),
                y="day_tweet_count:Q",
                text="day_tweet_count:Q",
            )
        )
        chart = base + text
    else:
        chart = base
    st.altair_chart(chart, width="stretch")

    summary_html = build_daytrend_ai_summary(day_df, history_df, history_cycles, base_range)
    if summary_html:
        st.markdown(summary_html, unsafe_allow_html=True)


def render_hour_section(hour_df: pd.DataFrame, show_values: bool):
    st.subheader("ğŸ•’ å°æ—¶çº§è¶‹åŠ¿ï¼ˆç¾ä¸œå°æ—¶ï¼‰")
    if hour_df.empty:
        st.info("å½“å‰ç­›é€‰åŒºé—´å†…æ²¡æœ‰æ•°æ®")
        return
    hover = alt.selection_point(fields=["date"], nearest=True, on="mouseover", empty="none")
    base_line = (
        alt.Chart(hour_df)
        .mark_line(interpolate="monotone")
        .encode(
            x=alt.X("date:T", title="Date"),
            y=alt.Y("hour_tweet_count:Q", title="Tweets per Hour"),
            color=alt.Color("hour_us:N", title="Hour (US)"),
        )
    )
    base_points = (
        alt.Chart(hour_df)
        .mark_point(size=50)
        .encode(
            x="date:T",
            y="hour_tweet_count:Q",
            color=alt.Color("hour_us:N", legend=None),
            tooltip=["date:T", "week_day:N", "hour_us:N", "hour_cn:N", "hour_tweet_count:Q"],
        )
        .add_params(hover)
    )
    rule = (
        alt.Chart(hour_df)
        .mark_rule(color="#888", strokeDash=[4, 4])
        .encode(x="date:T")
        .transform_filter(hover)
    )
    base = (base_line + base_points + rule).properties(height=320).interactive()
    if show_values:
        text = (
            alt.Chart(hour_df)
            .mark_text(fontSize=10, dy=-8)
            .encode(
                x="date:T",
                y="hour_tweet_count:Q",
                color=alt.Color("hour_us:N", legend=None),
                text="hour_tweet_count:Q",
            )
        )
        chart = base + text
    else:
        chart = base
    st.altair_chart(chart, width="stretch")


def render_weekday_section(day_df: pd.DataFrame, show_values: bool):
    st.subheader("ğŸ“… Weekday åˆ†å¸ƒï¼ˆæŒ‰æ—¥æ±‡æ€»ï¼‰")
    if day_df.empty:
        st.info("å½“å‰ç­›é€‰åŒºé—´å†…æ²¡æœ‰æ•°æ®")
        return
    weekday_stats = (
        day_df.groupby("week_day")["day_tweet_count"].sum().reindex(WEEKDAY_ORDER).reset_index().dropna()
    )
    base = (
        alt.Chart(weekday_stats)
        .mark_bar()
        .encode(x=alt.X("week_day:N", title="Weekday"), y=alt.Y("day_tweet_count:Q", title="Total Tweets"))
    )
    if show_values:
        labels = (
            alt.Chart(weekday_stats)
            .mark_text(dy=-8, fontSize=12)
            .encode(x="week_day:N", y="day_tweet_count:Q", text="day_tweet_count:Q")
        )
        chart = base + labels
    else:
        chart = base
    st.altair_chart(chart, width="stretch")


def render_heatmap(hour_df: pd.DataFrame, show_values: bool):
    st.subheader("ğŸ§Š Weekday Ã— Hour çƒ­åŠ›")
    if hour_df.empty:
        st.info("å½“å‰ç­›é€‰åŒºé—´å†…æ²¡æœ‰æ•°æ®")
        return
    hours = sorted(hour_df["hour_us"].unique())
    if not hours:
        st.info("æ— æœ‰æ•ˆå°æ—¶æ•°æ®")
        return
    idx = pd.MultiIndex.from_product([WEEKDAY_ORDER, hours], names=["week_day", "hour_us"])
    grid = (
        hour_df.groupby(["week_day", "hour_us"])["hour_tweet_count"]
        .sum()
        .reindex(idx, fill_value=0)
        .reset_index()
    )
    grid = grid[grid["hour_us"].notna()]
    grid["week_day"] = pd.Categorical(grid["week_day"], categories=WEEKDAY_ORDER, ordered=True)
    heat = (
        alt.Chart(grid)
        .mark_rect()
        .encode(
            x=alt.X("hour_us:O", title="Hour (US)"),
            y=alt.Y("week_day:O", title="Weekday", sort=WEEKDAY_ORDER),
            color=alt.Color("hour_tweet_count:Q", title="Tweets"),
            tooltip=["week_day", "hour_us", "hour_tweet_count"],
        )
    )
    if show_values:
        text = (
            alt.Chart(grid)
            .mark_text(fontSize=10)
            .encode(x="hour_us:O", y="week_day:O", text="hour_tweet_count:Q")
        )
        heat = heat + text
    st.altair_chart(heat, width="stretch")


def behavior_insights(day_df: pd.DataFrame, hour_df: pd.DataFrame):
    st.subheader("ğŸ¤– è¡Œä¸ºæ´å¯Ÿï¼ˆåŸºäºå½“å‰ç­›é€‰ï¼‰")
    if day_df.empty:
        st.info("æš‚æ— æ•°æ®å¯åˆ†æ")
        return
    top_weekday = day_df.groupby("week_day")["day_tweet_count"].mean().idxmax()
    low_weekday = day_df.groupby("week_day")["day_tweet_count"].mean().idxmin()
    max_day = day_df.loc[day_df["day_tweet_count"].idxmax()]
    min_day = day_df.loc[day_df["day_tweet_count"].idxmin()]

    top_hour = low_hour = None
    if not hour_df.empty:
        agg = hour_df.groupby("hour_us")["hour_tweet_count"].sum()
        top_hour = agg.idxmax()
        low_hour = agg.idxmin()

    dom_stats = (
        day_df.assign(day_of_month=day_df["date"].dt.day)
        .groupby("day_of_month")["day_tweet_count"]
        .mean()
    )
    dom_high = dom_stats.idxmax() if not dom_stats.empty else None
    dom_low = dom_stats.idxmin() if not dom_stats.empty else None

    st.markdown(
        f"""
        - **é«˜é¢‘å‘¨å‡ **ï¼š{top_weekday}ï¼Œ**ä½é¢‘å‘¨å‡ **ï¼š{low_weekday}
        - **é«˜å³°å°æ—¶ï¼ˆç¾ä¸œï¼‰**ï¼š{top_hour if top_hour is not None else 'â€”'}ï¼Œä½è°·å°æ—¶ï¼š{low_hour if low_hour is not None else 'â€”'}
        - **æœ€ç¹å¿™æ—¥æœŸ**ï¼š{max_day['date'].strftime('%Y-%m-%d')}ï¼ˆ{int(max_day['day_tweet_count'])} æ¡ï¼‰
        - **æœ€æ¸…æ·¡æ—¥æœŸ**ï¼š{min_day['date'].strftime('%Y-%m-%d')}ï¼ˆ{int(min_day['day_tweet_count'])} æ¡ï¼‰
        - **æŒ‰æœˆæ—¥ï¼ˆDay-of-Monthï¼‰å¹³å‡**ï¼šé«˜å³°åœ¨ {dom_high if dom_high is not None else 'â€”'} æ—¥ï¼Œä½è°·åœ¨ {dom_low if dom_low is not None else 'â€”'} æ—¥
        """
    )


def render_weekly_compare(
    day_natural_df: pd.DataFrame,
    base_start_date,
    show_values: bool,
    cycles: int = 3,
    weekday_order: List[str] = WEEKDAY_ORDER,
):
    st.subheader("ğŸ“ˆ å†å² 7 æ—¥å‘¨æœŸå¯¹æ¯”ï¼ˆæ—¥çº§ï¼‰")
    if day_natural_df.empty:
        st.info("æš‚æ— å†å²æ•°æ®ç”¨äºå¯¹æ¯”")
        return
    if isinstance(base_start_date, tuple):
        base_date = base_start_date[0]
    else:
        base_date = base_start_date
    base_date = base_date.date() if isinstance(base_date, datetime) else base_date
    lookup = (
        day_natural_df.groupby(day_natural_df["date"].dt.date)["day_tweet_count"].sum()
    )
    data: List[Dict] = []
    for idx in range(1, cycles + 1):
        cycle_start = base_date - timedelta(days=7 * idx)
        cycle_end = cycle_start + timedelta(days=7)
        cycle_label = f"{cycle_start.strftime('%m/%d')}â€“{cycle_end.strftime('%m/%d')}"
        for offset in range(7):
            current = cycle_start + timedelta(days=offset)
            weekday_label = current.strftime("%a")
            count = int(lookup.get(current, 0))
            data.append(
                {
                    "weekday": weekday_label,
                    "weekday_order": weekday_order.index(weekday_label),
                    "count": count,
                    "cycle": cycle_label,
                }
            )
    if not data:
        st.info("å†å²å‘¨æœŸæ•°æ®ä¸è¶³")
        return
    plot_df = pd.DataFrame(data)
    plot_df["weekday"] = pd.Categorical(plot_df["weekday"], categories=weekday_order, ordered=True)
    hover = alt.selection_point(fields=["weekday"], nearest=True, on="mouseover", empty="none")
    line = (
        alt.Chart(plot_df)
        .mark_line(point=True, interpolate="monotone")
        .encode(
            x=alt.X("weekday:O", sort=alt.Sort(weekday_order), title="", axis=alt.Axis(labelAngle=0)),
            y=alt.Y("count:Q", title="Posts per Day"),
            color=alt.Color("cycle:N", title="å†å²å‘¨æœŸ", legend=alt.Legend(orient="right")),
        )
    )
    points = (
        alt.Chart(plot_df)
        .mark_point(size=60)
        .encode(
            x=alt.X("weekday:O", sort=alt.Sort(weekday_order)),
            y="count:Q",
            color=alt.Color("cycle:N", legend=alt.Legend(title="å†å²å‘¨æœŸ", orient="right")),
            tooltip=["cycle:N", "weekday:N", "count:Q"],
        )
        .add_params(hover)
    )
    rule = (
        alt.Chart(plot_df)
        .mark_rule(color="#888", strokeDash=[4, 4])
        .encode(x=alt.X("weekday:O", sort=alt.Sort(weekday_order)))
        .transform_filter(hover)
    )
    chart = (line + points + rule)
    summary = plot_df.groupby("weekday")["count"].mean()
    dispersion = plot_df.groupby("weekday")["count"].std().fillna(0)
    top_day = summary.idxmax()
    low_day = summary.idxmin()
    stable_day = dispersion.idxmin()

    if show_values:
        text = (
            alt.Chart(plot_df)
            .mark_text(fontSize=11, dy=-8)
            .encode(x="weekday:O", y="count:Q", color=alt.Color("cycle:N", legend=None), text="count:Q")
        )
        chart = chart + text
    st.altair_chart(chart, width="stretch")

    narrative = (
        f"<div style='font-family:SF Pro Display,Helvetica,sans-serif;background:rgba(255,255,255,0.18);"
        f"padding:12px 16px;border-radius:14px;margin-top:12px;'>"
        f"<b>AI è§‚å¯Ÿï¼š</b>åœ¨å½“å‰ {cycles} ä¸ªå†å²å‘¨æœŸä¸­ï¼Œ"
        f"<b>{top_day}</b> å¹³å‡æœ€æ´»è·ƒï¼ˆâ‰ˆ{summary[top_day]:.1f} æ¡/æ—¥ï¼‰ï¼Œ"
        f"<b>{low_day}</b> æœ€æ¸…æ·¡ï¼ˆâ‰ˆ{summary[low_day]:.1f} æ¡/æ—¥ï¼‰ã€‚"
        f"æ³¢åŠ¨æœ€å°çš„æ˜¯ <b>{stable_day}</b>ï¼ˆÏƒâ‰ˆ{dispersion[stable_day]:.1f}ï¼‰ï¼Œä»£è¡¨ç¨³å®šåŸºçº¿ã€‚"
        f"æ•´ä½“æ—¥å‡åˆ†å¸ƒçš„ç¦»å·®çº¦ Â±{(summary.max() - summary.mean()):.1f} æ¡ï¼Œå¯æ®æ­¤åˆ¤æ–­é«˜ä½å³°æ—¶é—´æ®µã€‚"
        "</div>"
    )
    st.markdown(narrative, unsafe_allow_html=True)


def render_cycle_totals(
    bucket_df: pd.DataFrame,
    base_range,
    cycles: int,
    show_values: bool,
):
    st.subheader("ğŸ“Š å†å² 7 æ—¥å‘¨æœŸæ€»é‡ï¼ˆ12PMâ†’12PMï¼‰")
    if bucket_df.empty:
        st.info("æš‚æ— ç¬¦åˆç­›é€‰æ¡ä»¶çš„ 12PM å‘¨æœŸæ•°æ®")
        return

    base_end = base_range[1]
    base_end = base_end.date() if isinstance(base_end, datetime) else base_end
    bucket_df = bucket_df.copy()
    bucket_df["date"] = pd.to_datetime(bucket_df["date"]).dt.date

    records = []
    for idx in range(1, cycles + 1):
        cycle_start = base_end - timedelta(days=7 * idx)
        cycle_end = cycle_start + timedelta(days=7)
        mask = (bucket_df["date"] >= cycle_start) & (bucket_df["date"] < cycle_end)
        total = int(bucket_df.loc[mask, "day_tweet_count"].sum())
        label = f"{cycle_start.strftime('%m/%d')} 12PMâ€“{cycle_end.strftime('%m/%d')} 12PM"
        records.append({"cycle": label, "order": idx, "total": total})

    if not records:
        st.info("å†å²å‘¨æœŸæ•°æ®ä¸è¶³")
        return

    plot_df = pd.DataFrame(records)
    plot_df = plot_df.sort_values("order", ascending=False)
    hover = alt.selection_point(fields=["cycle"], nearest=True, on="mouseover", empty="none")
    line = (
        alt.Chart(plot_df)
        .mark_line(point=True, interpolate="monotone")
        .encode(
            x=alt.X("cycle:N", sort=list(plot_df["cycle"]), title="", axis=alt.Axis(labelAngle=0)),
            y=alt.Y("total:Q", title="è¿‡å» 7 å¤©æ€»å‘æ¨"),
        )
    )
    points = (
        alt.Chart(plot_df)
        .mark_point(size=70)
        .encode(
            x=alt.X("cycle:N", sort=list(plot_df["cycle"])),
            y="total:Q",
            color=alt.Color("cycle:N", title="æ—¶é—´åŒºé—´", legend=alt.Legend(orient="right")),
            tooltip=["cycle:N", "total:Q"],
        )
        .add_params(hover)
    )
    rule = (
        alt.Chart(plot_df)
        .mark_rule(color="#888", strokeDash=[4, 4])
        .encode(x="cycle:N")
        .transform_filter(hover)
    )
    chart = line + points + rule
    if show_values:
        text = (
            alt.Chart(plot_df)
            .mark_text(fontSize=11, dy=-8)
            .encode(x="cycle:N", y="total:Q", text="total:Q")
        )
        chart = chart + text
    st.altair_chart(chart, use_container_width=True)

    if not plot_df.empty:
        max_row = plot_df.loc[plot_df["total"].idxmax()]
        min_row = plot_df.loc[plot_df["total"].idxmin()]
        trend = "ä¸Šå‡" if plot_df.iloc[0]["total"] >= plot_df.iloc[-1]["total"] else "å›è½"
        st.markdown(
            f"<div style='font-family:SF Pro Display,Helvetica,sans-serif;background:rgba(255,255,255,0.18);"
            f"padding:12px 16px;border-radius:14px;margin-top:12px;'>"
            f"<b>AI è§‚å¯Ÿï¼š</b>æœ€é«˜å‘¨æœŸå‡ºç°åœ¨ <b>{max_row['cycle']}</b>ï¼ˆ{max_row['total']} æ¡ï¼‰ï¼Œ"
            f"æœ€ä½å‘¨æœŸä¸º <b>{min_row['cycle']}</b>ï¼ˆ{min_row['total']} æ¡ï¼‰ï¼Œ"
            f"æ•´ä½“èµ°åŠ¿å‘ˆç° <b>{trend}</b>ï¼Œå¯ä½œä¸ºç›˜å£é«˜ä½ä½å‚è€ƒã€‚"
            "</div>",
            unsafe_allow_html=True,
        )


def summarize_weekday_profile(frame: pd.DataFrame | None):
    if frame is None or frame.empty:
        return None
    temp = frame.copy()
    if "week_day" not in temp.columns and "date" in temp.columns:
        temp["week_day"] = pd.to_datetime(temp["date"]).dt.strftime("%a")
    avg = temp["day_tweet_count"].mean()
    weekday_means = (
        temp.groupby("week_day")["day_tweet_count"].mean().reindex(WEEKDAY_ORDER)
    )
    parts = []
    for wd in WEEKDAY_ORDER:
        val = weekday_means.get(wd)
        if pd.isna(val):
            continue
        parts.append(f"{WEEKDAY_CN.get(wd, wd)} {val:.1f}")
    breakdown = "ï½œ".join(parts)
    return avg, breakdown


def build_daytrend_ai_summary(
    current_df: pd.DataFrame,
    history_df: pd.DataFrame | None,
    history_cycles: int,
    base_range,
):
    sections = []
    all_frames: List[pd.DataFrame] = []
    current_label = ""
    if base_range is not None:
        start_val, end_val = base_range
        if not isinstance(start_val, datetime):
            start_val = datetime.combine(start_val, datetime.min.time())
        if not isinstance(end_val, datetime):
            end_val = datetime.combine(end_val, datetime.min.time())
        current_label = f"ï¼ˆ{start_val.strftime('%m/%d')}â€“{end_val.strftime('%m/%d')}ï¼‰"

    if current_df is not None and not current_df.empty:
        all_frames.append(current_df)
        current_stats = summarize_weekday_profile(current_df)
        if current_stats:
            avg, breakdown = current_stats
            sections.append(f"<b>æœ¬å‘¨æœŸ{current_label}</b>ï¼šæ—¥å‡ {avg:.1f} æ¡ï¼›{breakdown}")

    if (
        history_df is not None
        and not history_df.empty
        and base_range is not None
        and history_cycles > 0
    ):
        hist = history_df.copy()
        hist["date"] = pd.to_datetime(hist["date"])
        base_start_raw = base_range[0]
        if isinstance(base_start_raw, datetime):
            base_start_date = base_start_raw.date()
        else:
            base_start_date = base_start_raw
        history_frames = []
        for idx in range(1, history_cycles + 1):
            cycle_start = base_start_date - timedelta(days=7 * idx)
            cycle_end_inclusive = base_start_date - timedelta(days=7 * (idx - 1))
            mask = (
                (hist["date"].dt.date >= cycle_start)
                & (hist["date"].dt.date <= cycle_end_inclusive)
            )
            subset = hist.loc[mask]
            stats = summarize_weekday_profile(subset)
            if not stats:
                continue
            avg, breakdown = stats
            label = (
                f"å†å²å‘¨æœŸ {idx}ï¼ˆ{cycle_start.strftime('%m/%d')}â€“"
                f"{cycle_end_inclusive.strftime('%m/%d')}ï¼‰"
            )
            sections.append(f"<b>{label}</b>ï¼šæ—¥å‡ {avg:.1f} æ¡ï¼›{breakdown}")
            history_frames.append(subset)

        if history_frames:
            all_frames.extend(history_frames)

    if all_frames:
        combined = pd.concat(all_frames, ignore_index=True)
        combined_stats = summarize_weekday_profile(combined)
        if combined_stats:
            avg, breakdown = combined_stats
            sections.append(f"<b>å…¨éƒ¨å‘¨æœŸ</b>ï¼šæ—¥å‡ {avg:.1f} æ¡ï¼›{breakdown}")

    if not sections:
        return ""
    return (
        "<div style='font-family:SF Pro Display,Helvetica,sans-serif;background:rgba(255,255,255,0.18);"
        "padding:12px 16px;border-radius:14px;margin-top:8px;'>"
        + "<b>AI è§‚å¯Ÿï¼š</b><br>"
        + "<br>".join(sections)
        + "</div>"
    )


def build_cycle_shortcuts(min_day: date, max_day: date, today: date):
    today = min(today, max_day)
    shortcuts = []
    month_cursor = date(min_day.year, min_day.month, 1)
    while month_cursor <= max_day:
        for anchor in ANCHOR_DAYS:
            try:
                start = date(month_cursor.year, month_cursor.month, anchor)
            except ValueError:
                continue
            if start < min_day or start > max_day:
                continue
            display_end = start + timedelta(days=7)
            actual_end = min(display_end, max_day)
            icon = "â­•ï¸" if start <= today else "âšªï¸"
            label = f"{icon} {start:%m/%d} â†’ {display_end:%m/%d}"
            shortcuts.append({"label": label, "start": start, "end": actual_end, "display_end": display_end})
        month_cursor = (month_cursor.replace(day=28) + timedelta(days=4)).replace(day=1)
    shortcuts.sort(key=lambda x: x["start"], reverse=True)
    return shortcuts


def render_cycle_forecast(
    day_bucket_full: pd.DataFrame,
    day_bucket_current: pd.DataFrame,
    history_bucket_scope: pd.DataFrame,
    history_cycles: int,
    cycle_start: date,
    cycle_actual_end: date,
    cycle_display_end: date,
):
    st.subheader("ğŸ”® å‘¨æœŸé¢„æµ‹")
    total_days = 7
    est_now = datetime.now(ZoneInfo("America/New_York")).replace(tzinfo=None)
    cycle_start_dt = midday_dt(cycle_start)
    full_end_dt = midday_dt(cycle_display_end)
    clamped_now = max(min(est_now, full_end_dt), cycle_start_dt)
    elapsed = clamped_now - cycle_start_dt
    remaining_time = max(full_end_dt - clamped_now, timedelta(0))
    elapsed_days_float = elapsed.total_seconds() / 86400
    remaining_days_float = remaining_time.total_seconds() / 86400
    progress_pct = min(100.0, (elapsed_days_float / total_days) * 100)
    elapsed_days_int = int(elapsed.total_seconds() // 86400)
    elapsed_hours_int = int((elapsed.total_seconds() % 86400) // 3600)
    remaining_days_int = int(remaining_time.total_seconds() // 86400)
    remaining_hours_int = int((remaining_time.total_seconds() % 86400) // 3600)
    st.caption(
        f"å½“å‰å‘¨æœŸï¼š{cycle_start:%m/%d} 12:00 â†’ {cycle_display_end:%m/%d} 12:00ï¼ˆESTï¼‰ï½œ "
        f"å·²è¿‡å» {elapsed_days_int} å¤© {elapsed_hours_int} å°æ—¶ ({progress_pct:.1f}%)ï¼Œå‰©ä½™çº¦ "
        f"{remaining_days_int} å¤© {remaining_hours_int} å°æ—¶"
    )

    day_bucket_current = day_bucket_current.copy()
    day_bucket_current["date"] = pd.to_datetime(day_bucket_current["date"]).dt.date
    actual_dates = sorted(day_bucket_current["date"].unique().tolist())
    actual_total = day_bucket_current["day_tweet_count"].sum()
    completed_days = len(actual_dates)
    candidate_dates = [cycle_start + timedelta(days=i) for i in range(total_days + 1)]
    remaining_dates = [
        d
        for d in candidate_dates
        if d not in actual_dates and d < cycle_display_end
    ]
    remaining_count = len(remaining_dates)
    remaining_offsets = [(d - cycle_start).days for d in remaining_dates]
    if completed_days > 0:
        avg_day = day_bucket_current["day_tweet_count"].mean()
        max_day = day_bucket_current["day_tweet_count"].max()
        min_day_val = day_bucket_current["day_tweet_count"].min()
    else:
        avg_day = max_day = min_day_val = 0
    forecast_avg = actual_total + avg_day * remaining_days_float
    forecast_max = actual_total + max_day * remaining_days_float
    forecast_min = actual_total + min_day_val * remaining_days_float

    def badge(text, color):
        return f"<span style='color:{color};font-weight:600;'>{text}</span>"

    avg_formula = f"{actual_total:.0f} + {avg_day:.1f} Ã— {remaining_days_float:.1f} = {forecast_avg:.1f}"
    max_formula = f"{actual_total:.0f} + {max_day:.1f} Ã— {remaining_days_float:.1f} = {forecast_max:.1f}"
    min_formula = f"{actual_total:.0f} + {min_day_val:.1f} Ã— {remaining_days_float:.1f} = {forecast_min:.1f}"

    summary_html = f"""
    <div style='padding:10px 14px;border-radius:14px;background:rgba(255,255,255,0.15);'>
    <div style='font-weight:600;margin-bottom:6px;'>åŸºäºå½“å‰å‘¨æœŸå‡å€¼ / å³°å€¼ / è°·å€¼</div>
    <ul style='padding-left:18px;margin:0;'>
      <li>å·²ç»Ÿè®¡ {badge(completed_days, '#0ea5e9')} å¤©ï¼Œç´¯è®¡ {badge(f"{actual_total:.0f}", '#1d4ed8')} æ¡ï¼›å‰©ä½™ {badge(f"{remaining_days_float:.1f}", '#0ea5e9')} å¤©ã€‚</li>
      <li>å‡å€¼ {badge(f"{avg_day:.1f}", '#22c55e')} æ¡/æ—¥ â‡’ {badge(avg_formula, '#22c55e')}ã€‚</li>
      <li>å³°å€¼ {badge(f"{max_day:.1f}", '#f97316')} æ¡/æ—¥ â‡’ {badge(max_formula, '#f97316')}ã€‚</li>
      <li>è°·å€¼ {badge(f"{min_day_val:.1f}", '#ec4899')} æ¡/æ—¥ â‡’ {badge(min_formula, '#ec4899')}ã€‚</li>
    </ul>
    </div>
    """
    st.markdown(summary_html, unsafe_allow_html=True)

    if remaining_dates:
        desc_items = []
        for d in remaining_dates:
            wd = d.strftime("%a")
            wd_cn = WEEKDAY_CN.get(wd, wd)
            desc_items.append(f"{wd_cn}ï¼ˆ{d:%m/%d}ï¼‰")
        end_label = f"{WEEKDAY_CN.get(cycle_display_end.strftime('%a'), cycle_display_end.strftime('%a'))}ï¼ˆ{cycle_display_end:%m/%d}ï¼‰ Â· æˆªè‡³ 12:00 PM"
        st.markdown(
            f"<div style='padding:10px 14px;border-radius:12px;background:rgba(255,255,255,0.12);margin-top:10px;'>"
            f"è·ç¦» {cycle_display_end:%m/%d} 12:00 PM ç»“æŸè¿˜æœ‰ <b>{remaining_count}</b> å¤©ï¼š"
            f"{'ï¼Œ'.join(desc_items)}ï¼›ç»ˆç‚¹ {end_label}ã€‚</div>",
            unsafe_allow_html=True,
        )

    # å†å²å‘¨æœŸç»´åº¦
    if history_cycles > 0:
        hist_cycles: List[Dict] = []
        history_bucket_scope = history_bucket_scope.copy()
        history_bucket_scope["date"] = pd.to_datetime(history_bucket_scope["date"]).dt.date
        for idx in range(1, history_cycles + 1):
            hist_start = cycle_start - timedelta(days=7 * idx)
            hist_end = hist_start + timedelta(days=7)
            hist_df = history_bucket_scope[
                (history_bucket_scope["date"] >= hist_start) & (history_bucket_scope["date"] < hist_end)
            ].copy()
            if hist_df.empty:
                continue
            label = f"å†å²å‘¨æœŸ {idx}"
            hist_df["cycle"] = label
            hist_cycles.append({"label": label, "start": hist_start, "df": hist_df})
        if hist_cycles:
            hist_all = pd.concat([c["df"] for c in hist_cycles], ignore_index=True)
            remaining_weekdays = [
                {
                    "weekday": d.strftime("%a"),
                    "weekday_cn": WEEKDAY_CN.get(d.strftime("%a"), d.strftime("%a")),
                    "label": d.strftime("%m/%d"),
                }
                for d in remaining_dates
            ]
            if remaining_weekdays:
                rows = []
                add_avg = add_max = add_min = 0.0
                for meta in remaining_weekdays:
                    wd_values = hist_all.loc[hist_all["week_day"] == meta["weekday"], "day_tweet_count"]
                    if wd_values.empty:
                        continue
                    avg = wd_values.mean()
                    mx = wd_values.max()
                    mn = wd_values.min()
                    add_avg += avg
                    add_max += mx
                    add_min += mn
                    rows.append(
                        f"{meta['weekday_cn']}ï¼ˆ{meta['label']}ï¼‰ï¼šå‡å€¼ {badge(f'{avg:.1f}', '#22c55e')} ï½œå³° "
                        f"{badge(f'{mx:.1f}', '#f97316')} ï½œè°· {badge(f'{mn:.1f}', '#ec4899')}"
                    )
                if rows:
                    hist_avg_formula = f"{actual_total:.0f} + {add_avg:.1f} = {actual_total + add_avg:.1f}"
                    hist_max_formula = f"{actual_total:.0f} + {add_max:.1f} = {actual_total + add_max:.1f}"
                    hist_min_formula = f"{actual_total:.0f} + {add_min:.1f} = {actual_total + add_min:.1f}"
                    st.markdown(
                        "<div style='padding:10px 14px;border-radius:14px;background:rgba(255,255,255,0.15);margin-top:12px;'>"
                        "<div style='font-weight:600;margin-bottom:6px;'>å†å²å‘¨æœŸå‚è€ƒï¼ˆæŒ‰å‰©ä½™å‘¨å‡ ï¼‰</div>"
                        + "<br>".join(rows)
                        + "<ul style='padding-left:18px;margin-top:10px;'>"
                        + f"<li>å†å²å‡å€¼ï¼š{badge(hist_avg_formula, '#22c55e')}ã€‚</li>"
                        + f"<li>å†å²å³°å€¼ï¼š{badge(hist_max_formula, '#f97316')}ã€‚</li>"
                        + f"<li>å†å²è°·å€¼ï¼š{badge(hist_min_formula, '#ec4899')}ã€‚</li>"
                        + "</ul></div>",
                        unsafe_allow_html=True,
                    )
                else:
                    st.info("å†å²å‘¨æœŸä¸­æš‚æœªæ‰¾åˆ°å¯¹åº”å‘¨å‡ çš„æ•°æ®")

                # æ¡£ä½é€Ÿç‡ä¸æ¦‚ç‡æ¨æ¼”
                elapsed_days = max(elapsed.total_seconds() / 86400, 1e-6)
                elapsed_hours = max(elapsed.total_seconds() / 3600, 1e-6)
                current_rate_day = actual_total / elapsed_days
                current_rate_hour = actual_total / elapsed_hours
                st.markdown(
                    "<div style='padding:10px 14px;border-radius:12px;background:rgba(255,255,255,0.12);"
                    "margin-top:12px;'>å½“å‰è¿è¡Œé€Ÿç‡ â‰ˆ "
                    f"{badge(f'{current_rate_day:.1f}', '#0ea5e9')} æ¡/æ—¥ ï½œ "
                    f"{badge(f'{current_rate_hour:.2f}', '#0ea5e9')} æ¡/å°æ—¶ã€‚</div>",
                    unsafe_allow_html=True,
                )

                bucket_samples = []
                if remaining_offsets:
                    for cycle in hist_cycles:
                        df_cycle = cycle["df"].set_index("date")
                        addition = 0.0
                        valid = True
                        for offset in remaining_offsets:
                            target_date = cycle["start"] + timedelta(days=offset)
                            if target_date not in df_cycle.index:
                                valid = False
                                break
                            vals = df_cycle.loc[[target_date], "day_tweet_count"]
                            if vals.empty:
                                valid = False
                                break
                            addition += float(vals.iloc[0])
                        if valid:
                            bucket_samples.append(actual_total + addition)

                if bucket_samples:
                    bucket_ranges = [(start, start + 19) for start in range(100, 500, 20)]
                    total_samples = len(bucket_samples)
                    rows_html = []
                    for start, end in bucket_ranges:
                        count = sum(1 for val in bucket_samples if start <= val <= end)
                        prob = count / total_samples
                        rows_html.append(
                            f"<tr><td>{start}â€“{end}</td><td>{prob*100:.1f}%</td></tr>"
                        )
                    over_count = sum(1 for val in bucket_samples if val >= 500)
                    over_prob = over_count / total_samples
                    rows_html.append(f"<tr><td>â‰¥500</td><td>{over_prob*100:.1f}%</td></tr>")
                    st.markdown(
                        "<div style='margin-top:12px;'>"
                        "<div style='font-weight:600;margin-bottom:6px;'>æ¡£ä½æ¦‚ç‡é¢„æµ‹ï¼ˆ20 æ¡/æ¡£ï¼‰</div>"
                        "<table style='width:100%;border-collapse:collapse;font-size:13px;'>"
                        "<tr style='text-align:left;border-bottom:1px solid rgba(255,255,255,0.2);'>"
                        "<th style='padding:4px;'>åŒºé—´</th><th style='padding:4px;'>æ¦‚ç‡</th></tr>"
                        + "".join(rows_html)
                        + "</table>"
                        "<div style='font-size:12px;color:rgba(255,255,255,0.7);margin-top:6px;'>"
                        "ä¾æ®å†å²å‘¨æœŸåœ¨ç›¸åŒå‰©ä½™å¤©æ•°ä¸Šçš„çœŸå®äº§å‡ºä¼°ç®—ã€‚</div>"
                        "</div>",
                        unsafe_allow_html=True,
                    )
                else:
                    st.info("å†å²å‘¨æœŸæ ·æœ¬ä¸è¶³ï¼Œæš‚æ— æ³•ä¼°è®¡æ¡£ä½æ¦‚ç‡ã€‚")
            else:
                st.info("å½“å‰å‘¨æœŸå·²å®Œæˆï¼Œå†å²é¢„æµ‹æ— éœ€å†ä¼°è®¡ã€‚")
        else:
            st.info("æ‰€é€‰å†å²å‘¨æœŸæš‚æ— å¯ç”¨æ•°æ®ã€‚")
    else:
        st.info("æœªé€‰æ‹©å†å²å‘¨æœŸï¼Œè·³è¿‡å†å²é¢„æµ‹ã€‚")


def render_weekly_hour_compare(
    hour_df: pd.DataFrame,
    base_range,
    show_values: bool,
    cycles: int = 3,
    weekday_order: List[str] = WEEKDAY_ORDER,
):
    st.subheader("ğŸ•’ å†å² 7 æ—¥å‘¨æœŸå¯¹æ¯”ï¼ˆå°æ—¶çº§ï¼‰")
    if hour_df.empty:
        st.info("æš‚æ— å°æ—¶çº§æ•°æ®")
        return
    base_start = base_range[0]
    base_date = base_start.date() if isinstance(base_start, datetime) else base_start
    hour_lookup = (
        hour_df.groupby([hour_df["date"].dt.date, "hour_us"])["hour_tweet_count"].sum()
    )
    data = []
    hour_detail_rows = []
    for idx in range(1, cycles + 1):
        cycle_start = base_date - timedelta(days=7 * idx)
        cycle_end = cycle_start + timedelta(days=7)
        cycle_label = f"{cycle_start.strftime('%m/%d')}â€“{cycle_end.strftime('%m/%d')}"
        for offset in range(7):
            day = cycle_start + timedelta(days=offset)
            weekday_label = day.strftime("%a")
            counts = []
            for hour in range(24):
                val = hour_lookup.get((day, hour), 0)
                counts.append(val)
                hour_detail_rows.append(
                    {"cycle": cycle_label, "weekday": weekday_label, "hour": hour, "count": val}
                )
            total = sum(counts)
            if total == 0:
                continue
            top_hour = max(range(24), key=lambda h: counts[h])
            data.append(
                {
                    "weekday": weekday_label,
                    "top_hour": top_hour,
                    "count_at_hour": counts[top_hour],
                    "cycle": cycle_label,
                }
            )
    if not data:
        st.info("å†å²å°æ—¶æ•°æ®ä¸è¶³")
        return
    plot_df = pd.DataFrame(data)
    plot_df["weekday"] = pd.Categorical(plot_df["weekday"], categories=weekday_order, ordered=True)
    hover = alt.selection_point(fields=["weekday"], nearest=True, on="mouseover", empty="none")
    line = (
        alt.Chart(plot_df)
        .mark_line(point=True, interpolate="monotone")
        .encode(
            x=alt.X("weekday:O", sort=alt.Sort(weekday_order), title="", axis=alt.Axis(labelAngle=0)),
            y=alt.Y("top_hour:Q", title="Peak Hour (US)", scale=alt.Scale(domain=[0, 23])),
            color=alt.Color("cycle:N", title="å‘¨æœŸ"),
        )
    )
    points = (
        alt.Chart(plot_df)
        .mark_point(size=60)
        .encode(
            x=alt.X("weekday:O", sort=alt.Sort(weekday_order)),
            y="top_hour:Q",
            color=alt.Color("cycle:N", legend=alt.Legend(title="å†å²å‘¨æœŸ", orient="right")),
            tooltip=[
                "cycle:N",
                "weekday:N",
                alt.Tooltip("top_hour:Q", title="Hour (US)"),
                alt.Tooltip("count_at_hour:Q", title="Tweets at Hour"),
            ],
        )
        .add_params(hover)
    )
    rule = (
        alt.Chart(plot_df)
        .mark_rule(color="#888", strokeDash=[4, 4])
        .encode(x=alt.X("weekday:O", sort=alt.Sort(weekday_order)))
        .transform_filter(hover)
    )
    chart = line + points + rule
    if show_values:
        text = (
            alt.Chart(plot_df)
            .mark_text(fontSize=11, dy=-8)
            .encode(
                x=alt.X("weekday:O", sort=alt.Sort(weekday_order)),
                y="top_hour:Q",
                color=alt.Color("cycle:N", legend=None),
                text=alt.Text("top_hour:Q", format=".0f"),
            )
        )
        chart = chart + text
    st.altair_chart(chart, width="stretch")

    detail_df = pd.DataFrame(hour_detail_rows)
    detail_df["weekday"] = pd.Categorical(detail_df["weekday"], categories=weekday_order, ordered=True)
    heatmap = (
        alt.Chart(detail_df)
        .mark_rect()
        .encode(
            x=alt.X("weekday:O", sort=alt.Sort(weekday_order), title="", axis=alt.Axis(labelAngle=0)),
            y=alt.Y("hour:O", title="Hour (US)", sort=list(range(24))),
            color=alt.Color("count:Q", title="Tweets"),
            tooltip=["cycle:N", "weekday:N", "hour:Q", "count:Q"],
        )
    )
    st.altair_chart(heatmap, width="stretch")

    weekday_hour_avg = detail_df.groupby(["weekday", "hour"])["count"].mean().reset_index()
    top_pairs = weekday_hour_avg.sort_values("count", ascending=False).head(3)
    low_pairs = weekday_hour_avg.sort_values("count", ascending=True).head(3)
    summary_text = (
        "<div style='font-family:SF Pro Display,Helvetica,sans-serif;background:rgba(255,255,255,0.18);"
        "padding:12px 16px;border-radius:14px;margin-top:12px;'>"
        "<b>AI è§‚å¯Ÿï¼š</b>çƒ­ç‚¹é›†ä¸­åœ¨ "
        + ", ".join(f"{row['weekday']} {int(row['hour']):02d}:00 (â‰ˆ{row['count']:.1f})" for _, row in top_pairs.iterrows())
        + "ï¼›å†·ç‚¹ä½äº "
        + ", ".join(f"{row['weekday']} {int(row['hour']):02d}:00 (â‰ˆ{row['count']:.1f})" for _, row in low_pairs.iterrows())
        + "ã€‚å¯ä¼˜å…ˆåœ¨çƒ­ç‚¹æ—¶æ®µåŠ ä»“ã€å†·ç‚¹æ—¶æ®µä½é¢‘ç›‘æ§ï¼Œä»¥æå‡èµ”ç‡æŠŠæ¡ã€‚"
        "</div>"
    )
    st.markdown(summary_text, unsafe_allow_html=True)


def render_detail(detail_df: pd.DataFrame):
    st.subheader("ğŸ“„ æ¸…æ´—æ˜ç»†ï¼ˆé™å®šåŒºé—´ï¼‰")
    st.info("æ˜ç»†è¯·é€šè¿‡ä¸Šæ–¹ä¸‹è½½æœ€æ–°æ¸…æ´— CSV æŸ¥çœ‹ï¼Œä»¥é¿å…å†—é•¿è¡¨æ ¼ã€‚")


def parse_weekday_from_text(text: str):
    for key, value in WEEKDAY_MAP.items():
        if key in text:
            return value
    return None


def parse_hour_from_text(text: str):
    match = re.search(r"(\d{1,2})\s*(?:ç‚¹|æ—¶|hour|å°æ—¶|:|ç‚¹é’Ÿ)", text)
    if match:
        hour = int(match.group(1))
        if 0 <= hour <= 23:
            return hour
    match = re.search(r"(\d{1,2})\s*h", text)
    if match:
        hour = int(match.group(1))
        if 0 <= hour <= 23:
            return hour
    return None


def parse_hour_window(text: str):
    range_match = re.search(r"(\d{1,2})\s*[-â€“~ï½è‡³åˆ°]\s*(\d{1,2})", text)
    if range_match:
        start = int(range_match.group(1))
        end = int(range_match.group(2))
        if 0 <= start <= 23 and 0 <= end <= 23:
            if end < start:
                start, end = end, start
            return list(range(start, end + 1))
    single = parse_hour_from_text(text)
    if single is not None:
        return [single]
    return []


def aggregate_day_stats(frame: pd.DataFrame, start_dt: datetime, end_dt: datetime):
    subset = frame[["content", "EDT_time", "Beijing_time", "year", "Month", "WeekDay", "Hour"]].copy()
    bucket = polymarket.build_day_bucket_stats(subset)
    bucket["date"] = pd.to_datetime(bucket["date"], format="%m/%d/%Y")
    bucket = bucket[(bucket["date"] >= start_dt) & (bucket["date"] <= end_dt)]

    natural = polymarket.build_natural_day_stats(subset)
    natural["date"] = pd.to_datetime(natural["date"], format="%m/%d/%Y")
    natural = natural[(natural["date"] >= start_dt) & (natural["date"] <= end_dt)]
    return bucket, natural


def build_history_day_scope(detail_scope: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
    empty_bucket = pd.DataFrame(columns=["date", "day_tweet_count", "week_day"])
    empty_natural = empty_bucket.copy()
    if detail_scope.empty:
        return empty_bucket, empty_natural

    scope_start = detail_scope["EST_dt"].min().floor("D")
    scope_end = detail_scope["EST_dt"].max().floor("D") + pd.Timedelta(hours=23, minutes=59, seconds=59)
    bucket, natural = aggregate_day_stats(detail_scope, scope_start.to_pydatetime(), scope_end.to_pydatetime())
    if "week_day" not in natural.columns:
        natural["week_day"] = natural["date"].dt.strftime("%a")
    if "week_day" not in bucket.columns:
        bucket["week_day"] = bucket["date"].dt.strftime("%a")
    return bucket, natural


def ai_cycle_analysis(query: str, detail_full: pd.DataFrame, base_start: datetime, cycles_default: int = 1):
    cycles_match = re.search(r"å†å²\s*(\d+)", query)
    cycles = int(cycles_match.group(1)) if cycles_match else cycles_default
    weekday = parse_weekday_from_text(query)
    hours = parse_hour_window(query)
    if weekday is None or not hours:
        return "è¯·åŒæ—¶åŒ…å«ç›®æ ‡å‘¨å‡ ï¼ˆå¦‚å‘¨ä¸‰ï¼‰ä»¥åŠå°æ—¶æˆ–å°æ—¶åŒºé—´ï¼ˆå¦‚9~12ç‚¹ï¼‰ã€‚"

    results = []
    base_date = datetime.combine(base_start.date(), datetime.min.time())
    for idx in range(1, cycles + 1):
        start = base_date - timedelta(days=7 * idx)
        end = start + timedelta(days=7)
        mask = (detail_full["EST_dt"] >= start) & (detail_full["EST_dt"] < end)
        subset = detail_full.loc[mask]
        subset = subset[(subset["WeekDay"] == weekday) & (subset["Hour"].isin(hours))]
        results.append((start.strftime("%Y-%m-%d"), (end - timedelta(seconds=1)).strftime("%Y-%m-%d"), len(subset)))

    summary_lines = [
        f"å‘¨æœŸ {i+1}: {start} â†’ {end}ï¼Œå‘æ¨ {count} æ¡"
        for i, (start, end, count) in enumerate(results)
    ]
    if len(hours) == 1:
        hour_label = f"{hours[0]:02d}:00"
    else:
        hour_label = f"{hours[0]:02d}:00â€“{hours[-1]:02d}:59"
    head = f"AI åˆ†æï¼šé’ˆå¯¹å†å² {cycles} ä¸ªå‘¨æœŸçš„ {weekday} {hour_label} å‘æ¨é‡"
    return head + "\n" + "\n".join(summary_lines)


def filter_data(
    day_bucket_df: pd.DataFrame,
    day_natural_df: pd.DataFrame,
    hour_df: pd.DataFrame,
    detail_df: pd.DataFrame,
    date_range: Tuple[datetime.date, datetime.date],
    weekday_filter,
    hour_filter,
):
    start_date, end_date = date_range
    start_dt = datetime.combine(start_date, datetime.min.time())
    end_dt = datetime.combine(end_date, datetime.max.time())

    hour_mask = (
        (hour_df["date"] >= start_dt)
        & (hour_df["date"] <= end_dt)
        & (hour_df["week_day"].isin(weekday_filter))
        & (hour_df["hour_us"].isin(hour_filter))
    )
    hour_filtered = hour_df.loc[hour_mask].copy()

    detail_mask = (
        (detail_df["EST_dt"] >= start_dt)
        & (detail_df["EST_dt"] <= end_dt)
        & (detail_df["WeekDay"].isin(weekday_filter))
        & (detail_df["Hour"].isin(hour_filter))
    )
    detail_filtered = detail_df.loc[detail_mask].copy()

    if not detail_filtered.empty:
        day_bucket_filtered, day_natural_filtered = aggregate_day_stats(detail_filtered, start_dt, end_dt)
    else:
        day_bucket_filtered = day_bucket_df.iloc[0:0].copy()
        day_natural_filtered = day_natural_df.iloc[0:0].copy()

    return day_bucket_filtered, day_natural_filtered, hour_filtered, detail_filtered, start_dt, end_dt


def main():
    st.set_page_config(page_title="Musk Tweet Analyzer", layout="wide")
    st.markdown(
        """
        <style>
        .stApp {
            background: linear-gradient(135deg, #f4f7fb, #e0e7ff 60%, #fdf2f8);
            color: #0f172a;
        }
        div.block-container {
            padding-top: 1rem;
            padding-bottom: 2rem;
        }
        .glass-panel, .glass-card {
            background: rgba(255,255,255,0.9);
            border: 1px solid rgba(148,163,184,0.4);
            box-shadow: 0 18px 35px rgba(15,23,42,0.12);
            border-radius: 22px;
            padding: 18px;
            margin-bottom: 18px;
            backdrop-filter: blur(10px);
            color: #0f172a;
        }
        .glass-panel h4, .glass-card h4, .glass-card h3, .glass-panel h3 {
            margin-top: 0;
            color: #0f172a;
        }
        .glass-panel label, .glass-card label, .glass-panel p, .glass-card p {
            color: #0f172a;
        }
        .glass-panel .stButton>button, .glass-card .stButton>button {
            background: linear-gradient(135deg,#2563eb,#22d3ee);
            color: #fff;
            border: none;
            border-radius: 999px;
            padding: 6px 14px;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )
    st.title("Musk æ¨æ–‡æ¸…æ´— + åˆ†æå·¥ä½œå°")

    if "ai_response" not in st.session_state:
        st.session_state["ai_response"] = ""
    if "ai_query_text" not in st.session_state:
        st.session_state["ai_query_text"] = ""
    if "ai_should_run" not in st.session_state:
        st.session_state["ai_should_run"] = False

    navigation_col, content_col = st.columns([1, 4])
    uploaded = None
    fetch_latest = None

    with navigation_col:
        with glass_block("glass-panel"):
            st.subheader("æ•°æ®æº")
            uploaded = st.file_uploader("ä¸Šä¼  XTracker åŸå§‹ CSVï¼ˆå¯é€‰ï¼‰", type=["csv"])
            fetch_latest = st.button("åœ¨çº¿è·å– XTracker æœ€æ–°æ•°æ®", use_container_width=True)

    clean_path, source_info = ensure_file(uploaded, fetch_latest=fetch_latest)
    if clean_path is None:
        return

    detail_df, day_bucket_df, day_natural_df, hour_df = load_clean_outputs(clean_path)
    min_day, max_day = day_natural_df["date"].min().date(), day_natural_df["date"].max().date()
    default_start = max(min_day, (max_day - timedelta(days=7)))
    today_local = datetime.now(ZoneInfo("Asia/Shanghai")).date()

    pending_range = st.session_state.pop("pending_cycle_range", None)
    pending_display_end = st.session_state.pop("pending_cycle_display_end", None)
    last_sidebar_range = st.session_state.get("last_sidebar_range", (default_start, max_day))
    last_main_range = st.session_state.get("last_main_range", (default_start, max_day))
    current_display_end = st.session_state.get("current_cycle_display_end", last_sidebar_range[0] + timedelta(days=7))
    if pending_range:
        last_sidebar_range = pending_range
        last_main_range = pending_range
        if pending_display_end:
            current_display_end = pending_display_end

    with navigation_col:
        with glass_block("glass-panel"):
            st.subheader("å¯¼èˆªä¸ç­›é€‰")
            section_label = st.radio("å¿«é€Ÿè·³è½¬", list(SECTION_OPTIONS.values()), index=0)
            section_key = [k for k, v in SECTION_OPTIONS.items() if v == section_label][0]

            date_range_sidebar = st.date_input(
                "æ—¥æœŸèŒƒå›´ï¼ˆEST 12PM è¾¹ç•Œï¼‰",
                value=last_sidebar_range,
                min_value=min_day,
                max_value=max_day,
            )
            last_sidebar_range = date_range_sidebar

            weekday_filter = st.multiselect("é€‰æ‹© Weekday", WEEKDAY_ORDER, default=WEEKDAY_ORDER)
            hour_options = sorted(hour_df["hour_us"].dropna().unique().tolist())
            hour_filter = st.multiselect("ç¾ä¸œå°æ—¶", hour_options, default=hour_options if hour_options else [])
            history_cycles = st.slider("å†å²å‘¨æœŸæ¡æ•°ï¼ˆæ¯æ¡=å‘å‰ 7 å¤©ï¼‰", min_value=1, max_value=12, value=4)
            show_values = st.checkbox("æ˜¾ç¤ºå›¾è¡¨æ•°å€¼æ ‡ç­¾", value=False)

            cycle_shortcuts = build_cycle_shortcuts(min_day, max_day, today_local)
            if cycle_shortcuts:
                st.markdown("#### ğŸ—“ ç›˜å£å¿«æ·å‘¨æœŸï¼ˆé€‰æ‹©å³åº”ç”¨ï¼‰")
                labels = [opt["label"] for opt in cycle_shortcuts]
                if "cycle_select_last" not in st.session_state:
                    st.session_state["cycle_select_last"] = labels[0]
                    st.session_state["current_cycle_display_end"] = cycle_shortcuts[0]["display_end"]
                prev_label = st.session_state.get("cycle_select_last", labels[0])
                selected_label = st.selectbox(
                    "é€‰æ‹©èµ·å§‹æ—¥æœŸ",
                    labels,
                    index=labels.index(prev_label) if prev_label in labels else 0,
                    key="cycle_select",
                )
                if selected_label != prev_label:
                    chosen = next(opt for opt in cycle_shortcuts if opt["label"] == selected_label)
                    st.session_state["pending_cycle_range"] = (chosen["start"], chosen["end"])
                    st.session_state["pending_cycle_display_end"] = chosen.get("display_end", chosen["end"])
                    st.session_state["cycle_select_last"] = selected_label
                    st.rerun()

            st.divider()
            st.markdown("### ğŸ¤– AI å‘¨æœŸé—®ç­”")
            ai_query = st.text_area(
                "è¾“å…¥æƒ³åˆ†æçš„è§„åˆ™",
                value=st.session_state.get("ai_query_text", ""),
                placeholder="ä¾‹ï¼šå†å²2ä¸ªå‘¨æœŸï¼Œå‘¨äºŒ 10 ç‚¹å‘æ¨å¤šå°‘ï¼Ÿ",
                height=110,
                key="ai_query_input",
            )
            if st.button("ç”Ÿæˆ AI åˆ†æ", key="ai_query_button"):
                st.session_state["ai_query_text"] = ai_query.strip()
                st.session_state["ai_should_run"] = True
            ai_output_placeholder = st.empty()
            ai_response = st.session_state.get("ai_response", "")
            if ai_response:
                formatted = ai_response.replace("\n", "<br>")
                ai_output_placeholder.markdown(
                    f"<div style='font-size:12px;background:rgba(255,255,255,0.08);padding:10px;border-radius:10px;'>{formatted}</div>",
                    unsafe_allow_html=True,
                )

    if isinstance(date_range_sidebar, tuple):
        date_range_sidebar = (date_range_sidebar[0], date_range_sidebar[1])
    else:
        date_range_sidebar = (date_range_sidebar, date_range_sidebar)

    weekday_filter = weekday_filter or WEEKDAY_ORDER
    hour_defaults = hour_options if hour_options else list(range(24))
    hour_filter = hour_filter or hour_defaults

    st.session_state["last_sidebar_range"] = last_sidebar_range
    st.session_state["last_main_range"] = last_main_range
    st.session_state["current_cycle_display_end"] = current_display_end

    with content_col:
        date_range_active = last_main_range
        st.session_state["last_main_range"] = last_main_range

        history_span_days = max(history_cycles, 1) * 7
        hist_start_date = date_range_active[0] - timedelta(days=history_span_days)
        hist_start_dt = datetime.combine(hist_start_date, datetime.min.time())
        hist_end_dt = datetime.combine(date_range_active[1], datetime.max.time())

        detail_scope_mask = (
            detail_df["WeekDay"].isin(weekday_filter)
            & detail_df["Hour"].isin(hour_filter)
            & (detail_df["EST_dt"] >= hist_start_dt)
            & (detail_df["EST_dt"] <= hist_end_dt)
        )
        detail_scope_df = detail_df.loc[detail_scope_mask].copy()

        hour_scope_mask = (
            hour_df["week_day"].isin(weekday_filter)
            & hour_df["hour_us"].isin(hour_filter)
            & (hour_df["date"] >= hist_start_dt)
            & (hour_df["date"] <= hist_end_dt)
        )
        hour_scope_df = hour_df.loc[hour_scope_mask].copy()

        history_bucket_scope, history_day_scope = build_history_day_scope(detail_scope_df)

        if st.session_state.get("ai_should_run"):
            query_text = st.session_state.get("ai_query_text", "").strip()
            if query_text:
                ai_source = detail_scope_df if not detail_scope_df.empty else detail_df
                anchor_dt = datetime.combine(date_range_active[1], datetime.min.time())
                st.session_state["ai_response"] = ai_cycle_analysis(
                    query_text, ai_source, anchor_dt, cycles_default=history_cycles
                )
            else:
                st.session_state["ai_response"] = "è¯·è¾“å…¥éœ€è¦åˆ†æçš„å‘¨å‡ ä¸å°æ—¶æè¿°ã€‚"
            st.session_state["ai_should_run"] = False

        (
            day_bucket_filtered,
            day_natural_filtered,
            hour_filtered,
            detail_filtered,
            start_dt,
            end_dt,
        ) = filter_data(
            day_bucket_df, day_natural_df, hour_df, detail_df, date_range_active, weekday_filter, hour_filter
        )

        if not day_natural_filtered.empty:
            first_weekday = (
                day_natural_filtered.sort_values("date")["week_day"].iloc[0]
            )
            start_idx = WEEKDAY_ORDER.index(first_weekday)
            dynamic_weekday_order = WEEKDAY_ORDER[start_idx:] + WEEKDAY_ORDER[:start_idx]
        else:
            dynamic_weekday_order = WEEKDAY_ORDER

        with glass_block():
            latest_data_dt = day_natural_df["date"].max()
            latest_time_str = latest_data_dt.strftime("%Y-%m-%d") if not pd.isna(latest_data_dt) else "æœªçŸ¥"
            st.caption(
                f"æ•°æ®æ¥æºï¼š{source_info['mode']}ï¼ˆ{source_info['name']}ï¼‰ï¼Œæœ€æ–°æ•°æ®æ—¶é—´ï¼š{latest_time_str}"
            )
            st.caption(f"ç­›é€‰èŒƒå›´ï¼š{start_dt:%Y-%m-%d} â†’ {end_dt:%Y-%m-%d}")
            st.download_button("ä¸‹è½½æœ€æ–°æ¸…æ´— CSV", data=clean_path.read_bytes(), file_name=clean_path.name)

            cycle_start = date_range_active[0]
            cycle_actual_end = date_range_active[1]
            cycle_display_end = st.session_state.get("current_cycle_display_end", cycle_actual_end)

            render_cst_clock()
            render_cycle_forecast(
                day_bucket_df,
                day_bucket_filtered,
                history_bucket_scope,
                history_cycles,
                cycle_start,
                cycle_actual_end,
                cycle_display_end,
            )
            metrics_overview(day_bucket_filtered, detail_filtered)

        with glass_block():
            render_historical_today_table(
                day_natural_filtered,
                history_day_scope,
                history_cycles,
                hour_scope_df,
                date_range_active[1],
            )

        if section_key == "overview":
            with glass_block():
                render_day_section(
                    day_natural_filtered,
                    show_values,
                    history_df=history_day_scope,
                    history_cycles=history_cycles,
                    base_range=date_range_active,
                )
            with glass_block():
                render_cycle_totals(history_bucket_scope, date_range_active, history_cycles, show_values)
            with glass_block():
                render_weekly_hour_compare(
                    hour_scope_df, date_range_active, show_values, history_cycles, dynamic_weekday_order
                )
            with glass_block():
                render_hour_section(hour_filtered, show_values)
            with glass_block():
                render_weekday_section(day_natural_filtered, show_values)
            with glass_block():
                render_heatmap(hour_filtered, show_values)
            with glass_block():
                behavior_insights(day_natural_filtered, hour_filtered)
            with glass_block():
                render_detail(detail_filtered)
        elif section_key == "daily":
            with glass_block():
                render_day_section(
                    day_natural_filtered,
                    show_values,
                    history_df=history_day_scope,
                    history_cycles=history_cycles,
                    base_range=date_range_active,
                )
        elif section_key == "weekly_compare_day":
            with glass_block():
                render_weekly_compare(
                    history_day_scope, date_range_active, show_values, history_cycles, dynamic_weekday_order
                )
        elif section_key == "weekly_cycle_total":
            with glass_block():
                render_cycle_totals(history_bucket_scope, date_range_active, history_cycles, show_values)
        elif section_key == "weekly_compare_hour":
            with glass_block():
                render_weekly_hour_compare(
                    hour_scope_df, date_range_active, show_values, history_cycles, dynamic_weekday_order
                )
        elif section_key == "hourly":
            with glass_block():
                render_hour_section(hour_filtered, show_values)
        elif section_key == "weekday":
            with glass_block():
                render_weekday_section(day_natural_filtered, show_values)
        elif section_key == "heatmap":
            with glass_block():
                render_heatmap(hour_filtered, show_values)
        elif section_key == "insight":
            with glass_block():
                behavior_insights(day_natural_filtered, hour_filtered)
        elif section_key == "detail":
            with glass_block():
                render_detail(detail_filtered)


if __name__ == "__main__":
    main()
